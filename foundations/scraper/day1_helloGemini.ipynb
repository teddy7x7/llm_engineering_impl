{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e153c01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key è®€å–æˆåŠŸï¼\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai  # Gemini SDK\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# 1. è¼‰å…¥ç’°å¢ƒè®Šæ•¸\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "# 2. æª¢æŸ¥ API Key (Gemini çš„ Key é€šå¸¸ä»¥ AIza é–‹é ­)\n",
    "if not api_key:\n",
    "    print(\"æ‰¾ä¸åˆ° API Key - è«‹æª¢æŸ¥ .env æª”æ¡ˆä¸­æ˜¯å¦æœ‰ GOOGLE_API_KEY\")\n",
    "elif not api_key.startswith(\"AIza\"):\n",
    "    print(\"æ‰¾åˆ° API Keyï¼Œä½†æ ¼å¼ä¼¼ä¹Žä¸æ­£ç¢ºï¼ˆGemini Key é€šå¸¸ä»¥ AIza é–‹é ­ï¼‰\")\n",
    "else:\n",
    "    print(\"API Key è®€å–æˆåŠŸï¼\")\n",
    "\n",
    "# 3. é…ç½® Gemini\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e63d60dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: models/gemini-2.5-flash\n",
      "Description: Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.\n",
      "\n",
      "Model Name: models/gemini-2.5-pro\n",
      "Description: Stable release (June 17th, 2025) of Gemini 2.5 Pro\n",
      "\n",
      "Model Name: models/gemini-2.0-flash\n",
      "Description: Gemini 2.0 Flash\n",
      "\n",
      "Model Name: models/gemini-2.0-flash-001\n",
      "Description: Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.\n",
      "\n",
      "Model Name: models/gemini-2.0-flash-exp-image-generation\n",
      "Description: Gemini 2.0 Flash (Image Generation) Experimental\n",
      "\n",
      "Model Name: models/gemini-2.0-flash-lite-001\n",
      "Description: Stable version of Gemini 2.0 Flash-Lite\n",
      "\n",
      "Model Name: models/gemini-2.0-flash-lite\n",
      "Description: Gemini 2.0 Flash-Lite\n",
      "\n",
      "Model Name: models/gemini-exp-1206\n",
      "Description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "\n",
      "Model Name: models/gemini-2.5-flash-preview-tts\n",
      "Description: Gemini 2.5 Flash Preview TTS\n",
      "\n",
      "Model Name: models/gemini-2.5-pro-preview-tts\n",
      "Description: Gemini 2.5 Pro Preview TTS\n",
      "\n",
      "Model Name: models/gemma-3-1b-it\n",
      "Description: \n",
      "\n",
      "Model Name: models/gemma-3-4b-it\n",
      "Description: \n",
      "\n",
      "Model Name: models/gemma-3-12b-it\n",
      "Description: \n",
      "\n",
      "Model Name: models/gemma-3-27b-it\n",
      "Description: \n",
      "\n",
      "Model Name: models/gemma-3n-e4b-it\n",
      "Description: \n",
      "\n",
      "Model Name: models/gemma-3n-e2b-it\n",
      "Description: \n",
      "\n",
      "Model Name: models/gemini-flash-latest\n",
      "Description: Latest release of Gemini Flash\n",
      "\n",
      "Model Name: models/gemini-flash-lite-latest\n",
      "Description: Latest release of Gemini Flash-Lite\n",
      "\n",
      "Model Name: models/gemini-pro-latest\n",
      "Description: Latest release of Gemini Pro\n",
      "\n",
      "Model Name: models/gemini-2.5-flash-lite\n",
      "Description: Stable version of Gemini 2.5 Flash-Lite, released in July of 2025\n",
      "\n",
      "Model Name: models/gemini-2.5-flash-image\n",
      "Description: Gemini 2.5 Flash Preview Image\n",
      "\n",
      "Model Name: models/gemini-2.5-flash-preview-09-2025\n",
      "Description: Gemini 2.5 Flash Preview Sep 2025\n",
      "\n",
      "Model Name: models/gemini-2.5-flash-lite-preview-09-2025\n",
      "Description: Preview release (Septempber 25th, 2025) of Gemini 2.5 Flash-Lite\n",
      "\n",
      "Model Name: models/gemini-3-pro-preview\n",
      "Description: Gemini 3 Pro Preview\n",
      "\n",
      "Model Name: models/gemini-3-flash-preview\n",
      "Description: Gemini 3 Flash Preview\n",
      "\n",
      "Model Name: models/gemini-3-pro-image-preview\n",
      "Description: Gemini 3 Pro Image Preview\n",
      "\n",
      "Model Name: models/nano-banana-pro-preview\n",
      "Description: Gemini 3 Pro Image Preview\n",
      "\n",
      "Model Name: models/gemini-robotics-er-1.5-preview\n",
      "Description: Gemini Robotics-ER 1.5 Preview\n",
      "\n",
      "Model Name: models/gemini-2.5-computer-use-preview-10-2025\n",
      "Description: Gemini 2.5 Computer Use Preview 10-2025\n",
      "\n",
      "Model Name: models/deep-research-pro-preview-12-2025\n",
      "Description: Preview release (December 12th, 2025) of Deep Research Pro\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    # Filter for models supporting content generation (generateContent)\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(f\"Model Name: {m.name}\")\n",
    "        print(f\"Description: {m.description}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8762d759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Hello there! It's so great to hear from you. Welcome!\n",
      "\n",
      "I'm here and ready to chat. How can I help you today, or what's on your mind?\n"
     ]
    }
   ],
   "source": [
    "# é¸æ“‡æ¨¡åž‹ \n",
    "model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "\n",
    "# 4. ç™¼é€è¨Šæ¯\n",
    "message = \"Hello, Gemini! This is my first ever message to you! Hi!\"\n",
    "\n",
    "# Gemini çš„å‘¼å«æ–¹å¼æ¯” OpenAI æ›´ç°¡æ½”\n",
    "response = model.generate_content(message)\n",
    "\n",
    "# 5. å°å‡ºçµæžœ\n",
    "print(\"-\" * 20)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6662021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ihower { blogging } â€“ ðŸ˜† ðŸ‘¨ðŸ»â€ðŸ’» âœ¨ ðŸš€ ðŸ’° \n",
      "\n",
      "è·³è‡³ä¸»è¦å…§å®¹\n",
      "ihower { blogging }\n",
      "ðŸ˜† ðŸ‘¨ðŸ»â€ðŸ’» âœ¨ ðŸš€ ðŸ’°\n",
      "éƒ¨è½æ ¼é¦–é \n",
      "é—œæ–¼æˆ‘\n",
      "æ–‡ç« åˆ†é¡ž\n",
      "AI é–‹ç™¼èª²ç¨‹ â†—ï¸\n",
      "æŠ€è¡“å¯«ä½œ â†—ï¸\n",
      "æŠ€è¡“å¯«ä½œ â†—ï¸\n",
      "AI Engineer é›»å­å ±\n",
      "AI Engineer çŸ¥è­˜åº«ç­†è¨˜ â†—ï¸\n",
      "Rails å¯¦æˆ°è–ç¶“ â†—ï¸\n",
      "Git ç‰ˆæœ¬æŽ§åˆ¶ â†—ï¸\n",
      "App é–‹ç™¼åŸºç¤Ž â†—ï¸\n",
      "è¿”å›ž\n",
      "æ„›å¥½ AI Engineer é›»å­å ±Â ðŸš€Â 2025 AI å¹´åº¦å›žé¡§ #34\n",
      "æ­¡è¿Žè¨‚é–± ðŸ“¬\n",
      "æ„›å¥½ AI Engineer é›»å­å ±\n",
      "éŽå¾€æœŸæ•¸é»žé€™\n",
      "ðŸ“š\n",
      "Hello! å„ä½ AI é–‹ç™¼è€…å¤§å®¶å¥½ ðŸ‘‹\n",
      "2026 æ–°å¹´å¿«æ¨‚ï¼Œé€™æœŸå…§å®¹åå‘ 2025 å¹´ AI å¹´åº¦å›žé¡§èˆ‡æ•´ç†ã€‚\n",
      "é–±è®€å…¨æ–‡\n",
      "ã€ˆæ„›å¥½ AI Engineer é›»å­å ±Â ðŸš€Â 2025 AI å¹´åº¦å›žé¡§ #34ã€‰\n",
      "ä½œè€…:\n",
      "ihower\n",
      "19 1 æœˆ, 2026\n",
      "19 1 æœˆ, 2026\n",
      "åˆ†é¡ž:\n",
      "AIE\n",
      "åœ¨ã€ˆæ„›å¥½ AI Engineer é›»å­å ±Â ðŸš€Â 2025 AI å¹´åº¦å›žé¡§ #34ã€‰\n",
      "ç™¼ä½ˆç•™è¨€\n",
      "Agentic Search: æœå°‹æŠ€è¡“ä¸æœƒæ¶ˆå¤±ï¼Œåªæ˜¯è®Šæˆ Agent å·¥å…·\n",
      "çœ‹äº†å…©å ´é—œæ–¼ Agentic Search çš„æ¼”è¬›ï¼Œåˆ†åˆ¥ä¾†è‡ª AWS OpenSearch çš„ John Handler å’Œ\n",
      "AI-Powered Search\n",
      "é€™æœ¬æ›¸çš„ä½œè€…\n",
      "Doug Turnbull\n",
      "(é€™æœ‰å¾ˆå¤šæª¢ç´¢çŸ¥è­˜æ–‡ç« ï¼Œè¶…è®š)ï¼Œå…©ä½éƒ½åœ¨æŽ¢è¨Ž: AI Agent æ˜¯å¦æ­£åœ¨å–ä»£å¹¾åå¹´ç´¯ç©çš„æœå°‹æ™ºæ…§?\n",
      "é–±è®€å…¨æ–‡\n",
      "ã€ˆAgentic Search: æœå°‹æŠ€è¡“ä¸æœƒæ¶ˆå¤±ï¼Œåªæ˜¯è®Šæˆ Agent å·¥å…·ã€‰\n",
      "ä½œè€…:\n",
      "ihower\n",
      "31 12 æœˆ, 2025\n",
      "1 1 æœˆ, 2026\n",
      "åˆ†é¡ž:\n",
      "LLM\n",
      "åœ¨ã€ˆAgentic Search: æœå°‹æŠ€è¡“ä¸æœƒæ¶ˆå¤±ï¼Œåªæ˜¯è®Šæˆ Agent å·¥å…·ã€‰\n",
      "ç™¼ä½ˆç•™è¨€\n",
      "æ„›å¥½ AI Engineer é›»å­å ±Â ðŸš€Â 2025 Q4 AI æ¨¡åž‹èˆ‡ Agent é–‹ç™¼ #33\n",
      "æ­¡è¿Žè¨‚é–± ðŸ“¬\n",
      "æ„›å¥½ AI Engineer é›»å­å ±\n",
      "éŽå¾€æœŸæ•¸é»žé€™\n",
      "ðŸ“š\n",
      "Hello! å„ä½ AI é–‹ç™¼è€…å¤§å®¶å¥½ ðŸ‘‹\n",
      "2025 Q4 å„å®¶é™¸çºŒæŽ¨å‡ºæ–°æ¨¡åž‹ï¼ŒSOTA æ¨¡åž‹è¼ªæµç•¶ã€‚ä»¥ä¸‹æ•´ç†æ–°æ¨¡åž‹æ¶ˆæ¯ï¼Œä»¥åŠé›†çµæˆ‘æœ€è¿‘ç™¼è¡¨çš„å…§å®¹ã€‚\n",
      "é–±è®€å…¨æ–‡\n",
      "ã€ˆæ„›å¥½ AI Engineer é›»å­å ±Â ðŸš€Â 2025 Q4 AI æ¨¡åž‹èˆ‡ Agent é–‹ç™¼ #33ã€‰\n",
      "ä½œè€…:\n",
      "ihower\n",
      "19 12 æœˆ, 2025\n",
      "20 12 æœˆ, 2025\n",
      "åˆ†é¡ž:\n",
      "AIE\n",
      "åœ¨ã€ˆæ„›å¥½ AI Engineer é›»å­å ±Â ðŸš€Â 2025 Q4 AI æ¨¡åž‹èˆ‡ Agent é–‹ç™¼ #33ã€‰\n",
      "ç™¼ä½ˆç•™è¨€\n",
      "AI Agent ç”¢å“é–‹ç™¼ä»ç„¶ä¸ç°¡å–®\n",
      "åœ¨è¬›å®Œ WebConf ä¹‹å¾Œï¼Œæˆ‘æœ‰ç¨®èŽ«åçš„ä¸å”èª¿æ„Ÿ: ä¸€æ–¹é¢ Vibe Coding è®“å¤§å®¶å¯«ç¨‹å¼è®Šç°¡å–®äº†ï¼Œäººäººéƒ½å¯ä»¥åš App äº†ï¼Œä¹Ÿå¾ˆå¤šäººè¬›ç¡¬æŠ€èƒ½ä¸é‡è¦äº†ã€‚ä½†å¦ä¸€æ–¹é¢ï¼Œæˆ‘è¦ºå¾—é–‹ç™¼ AI Agent ç”¢å“ä»æ˜¯éžå¸¸æœ‰æŠ€è¡“æŒ‘æˆ°æ€§çš„ï¼Œéœ€è¦çš„çŸ¥è­˜æŠ€èƒ½æ·±åº¦å»£åº¦ä¸€é»žéƒ½ä¸å°‘ã€‚\n",
      "æœ€è¿‘ä¹Ÿçœ‹åˆ°äº†å¹¾ç¯‡é—œæ–¼ AI Agent é–‹ç™¼çš„æ–‡ç« ï¼Œç™¼ç¾åœ‹å¤–æŠ€è¡“ç¤¾ç¾¤åœ¨ 2025 Q4 ä¹Ÿæœ‰é¡žä¼¼çš„é«”æ‚Ÿ: Agent ç”¢å“é–‹ç™¼è¨­è¨ˆé‚„æ˜¯å¾ˆé›£ã€‚\n",
      "ä¸æ˜¯ã€Œå¯«ç¨‹å¼å¾ˆé›£ã€é‚£ç¨®é›£ï¼Œè€Œæ˜¯ã€Œ95% çš„ AI Agent ç”¢å“ï¼Œé€²åˆ°æ­£å¼ç’°å¢ƒæœƒå¤±æ•—ã€é€™ç¨®é›£ã€‚å•é¡Œä¸åœ¨æ¨¡åž‹ä¸å¤ è°æ˜Žï¼Œè€Œåœ¨æ–¼å‘¨é‚Šçš„å·¥ç¨‹æž¶æ§‹: context ç®¡ç†ã€memoy è¨­è¨ˆã€éŒ¯èª¤è™•ç†ã€agent prompt æœ€ä½³åŒ–ã€èªžæ„æª¢ç´¢ã€è©•ä¼°å›žé¥‹æ©Ÿåˆ¶ç­‰ç­‰ï¼Œå¾ˆå¤šéƒ½æ˜¯å…¨æ–°é ˜åŸŸï¼Œä¸”æˆ°ä¸”èµ°çš„æƒ…æ³ã€‚æ¨¡åž‹åªèƒ½ç”¨å¹¾å€‹æœˆå°±è¦å‡ç´šæ›´æ›ï¼Œå¹¾å€‹æœˆå‰çš„ best practice ä¹Ÿå¯èƒ½æœƒè¢«æŽ¨ç¿»é‡æ–°æ€è€ƒã€‚\n",
      "ç¸½ä¹‹ï¼Œä»¥ä¸‹æˆ‘æ•´ç†å¹´åº•å››ç¯‡æˆ‘è¦ºå¾—é—œæ–¼ Agent é–‹ç™¼æ°›åœçš„ä¸éŒ¯æ–‡ç« :\n",
      "é–±è®€å…¨æ–‡\n",
      "ã€ˆAI Agent ç”¢å“é–‹ç™¼ä»ç„¶ä¸ç°¡å–®ã€‰\n",
      "ä½œè€…:\n",
      "ihower\n",
      "19 12 æœˆ, 2025\n",
      "19 12 æœˆ, 2025\n",
      "åˆ†é¡ž:\n",
      "LLM\n",
      "åœ¨ã€ˆAI Agent ç”¢å“é–‹ç™¼ä»ç„¶ä¸ç°¡å–®ã€‰\n",
      "ç™¼ä½ˆç•™è¨€\n",
      "å¯¦æˆ° AI Agents æ‡‰ç”¨é–‹ç™¼: TTFT å’Œ Prompt Caching\n",
      "2025/12/13 åœ¨\n",
      "WebConf Taiwan\n",
      "åˆ†äº«çš„æ¼”è¬›æŠ•å½±ç‰‡\n",
      "âž¡ï¸\n",
      "é€™è£¡ä¸‹è¼‰PDF(32mb)\n",
      "å¦‚æžœä½ é‚„æ²’æœ‰è¨‚é–±æˆ‘çš„é›»å­å ±ï¼Œ\n",
      "æ­¡è¿Žè¨‚é–± ðŸ“¬\n",
      "æ„›å¥½ AI Engineer é›»å­å ±ã€‚\n",
      "è­°ç¨‹ä»‹ç´¹:\n",
      "AI Agent æ­£é€æ¼¸æˆç‚º Web æ‡‰ç”¨ç”¢å“ä¸­çš„é—œéµåŠŸèƒ½ï¼Œå¾žå·¥ä½œæµç¨‹åˆ° AI æ™ºæ…§åŠ©ç†ï¼Œé–‹ç™¼è€…é–‹å§‹è®“ Agent èžå…¥ Web æ‡‰ç”¨çš„ç³»çµ±æž¶æ§‹ã€‚\n",
      "å»¶çºŒåŽ»å¹´ã€Œæ·ºè«‡ AI Agents æ‡‰ç”¨é–‹ç™¼ã€çš„åŸºç¤Žï¼Œä»Šå¹´æˆ‘å€‘å¾žå¯¦æˆ°è§’åº¦å‡ºç™¼ï¼Œä»‹ç´¹å¦‚ä½•åœ¨ Web ç’°å¢ƒä¸‹é–‹ç™¼ã€éƒ¨ç½²èˆ‡æœ€ä½³åŒ– AI Agent ç³»çµ±ã€‚æœ¬æ¬¡åˆ†äº«å°‡ä»¥\n",
      "Python FastAPI + OpenAI Agents SDK + å‰å¾Œ\n"
     ]
    }
   ],
   "source": [
    "from scraper import fetch_website_contents\n",
    "ihower = fetch_website_contents(\"https://ihower.tw/blog/\")\n",
    "print(ihower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f173cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a snarky assistant that analyzes the contents of a website,\n",
    "and provides a short, snarky, humorous summary, ignoring text that might be navigation related.\n",
    "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bdd4c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our user prompt\n",
    "\n",
    "user_prompt_prefix = \"\"\"\n",
    "Here are the contents of a website.\n",
    "Provide a short summary of this website.\n",
    "If it includes news or announcements, then summarize these too.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94f7e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def prompt_for(website: str) -> str:\n",
    "    return f\"\"\"\n",
    "{system_prompt}\n",
    "\n",
    "{user_prompt_prefix}\n",
    "{website}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81683b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Welcome to \"ihower { blogging },\" a delightful digital oasis where it seems the future has already happened! This site is a veritable shrine to all things AI, AI Agents, and the apparently grueling life of an \"AI Engineer.\"\n",
       "\n",
       "**News & Announcements:**\n",
       "The latest scoop from this time-traveling blog includes a \"2025 AI Year in Review\" published on *January 19, 2026* (impressive foresight!), the profound revelation on *December 31, 2025*, that search tech isn't going anywhere, it's just becoming an Agent's minion. We also get a Q4 2025 AI model roundup and, perhaps most groundbreaking, the shocking truth that developing AI Agent products is, contrary to popular belief, \"still not simple.\" Who knew?!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def summarize(url: str) -> str:\n",
    "    website = fetch_website_contents(url)\n",
    "\n",
    "    model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "    response = model.generate_content(\n",
    "        prompt_for(website)\n",
    "    )\n",
    "\n",
    "    return response.text\n",
    "\n",
    "def display_summary(url: str):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))\n",
    "\n",
    "display_summary(\"https://ihower.tw/blog/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
